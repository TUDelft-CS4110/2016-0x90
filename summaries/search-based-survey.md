
### Metaheursitic Search Applications
**Goals:**
 - Coverage of the code.
 - Exercise a specific feature of the program.
 - Disprove grey-box properties.
 - Verify non-functional properties.

### Metaheursitic Search Techniques
Solutions should be encoded such that they can be manipulated by the search and *neighbouring* solutions can be compared. 
Using an *objective function*, *good* solutions are distinguished from *bad* solutions.
The ojective function provides guidance to the search for solutions.

#### Hill Climbing
This is a local search algorithm that starts off at a random starting point and tries to look at neighbouring points in the search space to improve the solution.
It is simple and fast. However, it often reaches sub-optimal solutions when there are many local optimal.
This can be slightly avoided by starting at multiple random starting points.

#### Simulated Annealing
Simulated Annealing is similar to Hill Climbing, but probabilistically accepts poorer solutions.
The technique does not always choose the optimal solution, but has a given probability that chooses worse solutions. 
This allows us to find solutions that are "deeper" in the search path.
It starts off with lots of freedom in movement (high probability to choose worse solutions), but limits its movement (low probability to choose worse solutions) as the search progresses.

#### Evolutionary Algorithms
##### Evolution Strategies
Evolution Strategies use mutation: a process of randomly modifying solutions. 

##### Genetic Algorithms
In Genetic Algorithms the search is driven by *recombination*, a mechanism of exchange of information between solutions to create new ones.
Genetic Algorithms keep track of a population of solutions, not only one solution. 
This allows for the sampling of a larger search space.
The population is combined and mutated to evolve successive populations.
Favour 'fitter' solutions to be combined and form even better solutions.
Choosing 'fitter' solutions too heavily can have a negative effect and reduce diversity and can cause *premature convergence*.

**Fitness-proprotionate selection:**
The number of times an individual is selected is proportional to its relative fitness.
Difficulties: maintaining a constant *selective pressure* (grade of selecting different solutions).

**Linear Ranking:**
Individuals are sorted by fitness and a selective bias of *Z* is applied to each of the individuals.
For Z holds: 1 < Z ≤ 2. The linear ranking allocates a selective bias of Z to the top individual, a bias of 1.0 to the median individual, and 2 − Z to the bottom individual.
This differs from fitness-proportionate selection in the sense that a constant bias is applied and thus the selective pressure is more constant and controlled.

**Tournament Selection:** 
In Tournament Selection two individuals are chosen at random. A random number is then chosen and compared to the probability of the better individual being selected.
Afterwards the winner is the parent of the other individual.
Once all the parents have been selected, recombination forms the next generation.
Optionally random crossover is applied, sending children into a new population.
After the recombination, mutation is applied flipping random bits of binary strings with a certain probability.

##### Advanced Encodings and Operators
Problem in encoding: solutions can be close together, but their encoding can be very different.
Real-valued representations tend to outperform binary encodings and are used most often in Evolution Strategies.

### Structural (White-Box) Testing
White-Box Testing is the process of deriving tests from the internal structure of the software under test.

#### Static Structural Test Data Generation
Data is generated by analysis of the internal without actually executing the program.

##### Symbolic Execution
Uses the process of assigning expressions to program variables as a path through the code structure to derive a constraint system in terms of the input variables which describe the conditions necessary for the traversal of a given path.

Backwards path traversal has an advantage over forward traversal in the sense that no storage is required for intermediate symbolic expressions of variables. Forward traversal however allows for early detection of infeasible paths.

Constraint satisfaction problems are NP-complete. However, combinations of heuristics and linear programming techniques can be applied to lighten the process.

Loops are executed *K* times, where *K* is specified by the tester or system.

Procedure calls can be inlined as a solution, however the number of paths can grow rapidly with this approach

##### Domain Reduction
*Constraint-based Testing* builds up a constraint system which describes the test goal. 
*Reachability constraints* withing the constraint system describe the conditions required for the reachability of statements.
*Necessity constraints* describe the conditions that will kill a mutant.

By using Symbolic Execution we can develop constraints in terms of input variables and perform *Domain Reduction*  to attempt a solution to the constraints. 
> Large search space ---constraints---> Reduction of search space

##### Dynamic Domain Reduction
Dynamic Domain Reduction is a *static analysis technique* that starts with domains of the input variables and reduce these dynamically during the symbolic execution stage in contrast to normal Domain Reduction. 

*This technique still suffers from difficulties with computed storage locations, loops and non-ordinal variable types(e.g. Enums).*

#### Dynamic Structural Test Data Generation
*Dynamic methods* use input to execute a program and instrumentation to observe the results.
Many of the issues present in Symbolic Execution are resolved by directly resolving e.g. pointer values and array subscripts.

##### Random Testing
Executes the program with random inputs and observes executed program structures.
When using this technique, code that has low probability of being executed is often not covered, in such cases more directed search techniques are required.

###### Applying Local Search
In the Local Search technique, the tester selects a path through the program and produces a straight-line version of that path.
Path constraints are constructed with a constant for each constraint estimating the satisfiability of the constraint.
A function *f* is constructed out of all of these constraints.
*f* provides an estimate of the satisfiability of all constraints.
Using numerical maximisation techniques, the input values are maximized to satisfy as many constraints as possible.
One major drawback of this is that run-time errors can occur, since the dependency between constraints are not taken into account, which could create sequences that in practice are impossible to execute.

Improvements to this technique emerged to resolve this problem.
The search was now targeted with the satisfaction of each constraint instead of all the constraints. 
If during the execution an undesired branch is taken, a local search is started that is targeted to minimize branch distance of the desired branch, also known as the *branch distance*.
Creating these inputs is done using the *alternating variable* method, that starts with an *exploratory phase* which probes neighbouring constraints by increasing or decreasing only that specific variable.
If the move leads to an improved objective value, a *pattern phase* is entered.
In this phase a larger move is made in the direction of the improvement, this is repeated until a minimum for that objective function is found for that variable.
After this is complete, other variable are explored.

These techniques suffer however from one main problem: the final solution is highly dependent on the starting solution, which can be very wasteful if unfavorable values are chosen.
A solution to this is the creation of an *influences graph*, that is created via dynamic data flow analysis and is used to detect which input variable influence the outcome at a branching node.
Additionally a risk analysis on the input variables can be performed to decided if they could violate the already successful sub-path.

###### The Goal-Oriented Approach
A Goal-Oriented Approach is a technique with a set goals(e.g. statement coverage).
Branches are prioritized by analyzing the control flow graph.

A branch is *critical*, when if chosen, the control flow won't reach the target node.
The objective function is then associated with the alternative branch.
The alternating variable search method is used, if the required inputs cannot be found, the process terminates with the target unexecuted.

A branch is *semi-critical* if it leads to a target node via the back edge of a loop. The alternative branch will lead directly to the target node.
Inputs for this are sought, but when they are not found, the alternative branch is iterated next.

A branch is *non-essential*, when it is neither *critical* nor *semi-critical*.
These branches do not affect the reachability of target node and are thus are allowed to be executed.

The Goal-Oriented Approach suffers from similar problems as the Local Search approach. The removal of the requirement to select a path introduces new ways in which the test data search can fail.
Instead of performing local searches, this technique can also use global search with Genetic Algorithms, but even these have their problems.

Main problem: data dependencies are not taken into account. An attempt to solve this solution is made in the Chaining Approach

###### The Chaining Approach
Chaining uses an *event sequence* as a intermediate means of deciding the type of path required to reach the target node. 
An *event sequence* is a succession of nodes that should be executed.
Initial sequence consists of *start* and *target* nodes.
This sequence is filled in once the test data search encounters difficulties.

**Event Sequence:** `<e_1, e_2, ... e_k>`, where `e_i = (n_i, C_i)` where `n_i in N` is a program node and `C_i` is a set of variables referred to as a constraint set.

Every two adjacent events should not have variables in the constraint set modified, this ensures that a *definition-clear path* must be taken from one node to the other node.

A branch is *critical* if there does not exist a definition-clear path between the two program nodes, even though such a path does exist via another branch.
A branch is *semi-critical* if it is not-critical, the target node is control dependent on path p and there does not exist an acyclic definition-clear path.
A branch is *non-essential* if it is none of the above.

When inputs cannot be found to change the flow of control such that a critical branch is avoided, the starting node is declared as being a problem node.
The technique then searches for alternative event sequences.

The Chaining Approach organises generated event sequences in a tree form. 
In this tree, the root node represents the initial event sequence and subsequent nodes are the resulting event sequences of all the corresponding problem nodes.
Backtracking techniques of depth *n* can be used in more complicated instances to look for last definition statements of variables.
The tree is explored using a depth-first strategy with a specified depth limit.
This technique covers a larger set of programs than the Goal-Oriented Approach, but as search times increase, local search can become trapped in difficult search spaces.

##### Applying Simulated Annealing
The "neighbourliness" structure of the integer and real variables is defined as the range of values around each individual value.
Boolean, enumerated types and all other order insignificant variables are considered as neighbours.
The objective function is the branch distance of the required branch when control flow diverges from the intended path. 
To reduce search becoming stuck in a local optima, the restriction that a solution must conform to an already existing sub-path is lifted.

##### Applying Evolutionary Algorithms
####### Coverage-Oriented Approaches
Coverage-Oriented Approaches work by rewarding on the basis of covered program structures.
Search tends to reward long paths through the test subject.
When using this technique, generally there is a lack of guidance provided for structures, which are only executed with values from a small portion of the overall input domain.
Therefore, it is difficult to expect full coverage of these techniques for any non-trivial programs.

####### Structure-Oriented Approaches
Structure-Oriented Approaches take a *divide and conquer* approach to obtain full coverage. In this approach, a separate search is done for each uncovered element.

**Branch-Distance-Oriented Approaches**: 
Branch-Distance-Oriented Approaches use branch predicates in combination with Random Search or Genetic Algorithms for the more difficult cases.
A path is chosen and the relevant branch predicates are extracted. A Genetic Algorithm is then used to find input data that satisfies all branch predicates at once.
Since this technique requires rigid constraints, the chance of getting stuck in local optima is high.
It would be better if more feedback could be provided via the objective function.
This is where control oriented approaches come into play.

**Control-Oriented Approaches**:
In this technique, the objective function considers branching nodes that need to be executed to cover a desired structure.
This technique needs the control dependence graph of the test subject to identify each of these branching nodes.
The problem with the Control-Oriented Approach is that the objective function gives no guidance on how to change the flow of execution at control dependent nodes, since no distance information is exploited from branch predicates.

**Combined Approaches**
Combined Approaches make use of both branch distance and control information for the objective function.
The technique suffers a bit from local optima, but this can be resolved by using a form of *approximation level*.
The result looks quite a bit like the Control-Oriented approach, but by using branch distance calculations the objective function is greatly improved.

##### Objective Functions for Different Structural Coverage Criteria
Structural criteria are divided into four categories, where the general objective function is defined as: `approach_level + m_branch_dist`.
These two variables depend on the coverage type in question.

**Node-Oriented:**
Aim to cover specific nodes of the control flow graph.

**Path-Oriented:**
Require the execution of specific paths through the control flow graph.

**Node-Path-Oriented:**
Include branch coverage and LCSAJ (linear code sequence and jump) coverage.

**Node-Node-Oriented:**
Aim to execute a certain sequence of nodes through the control flow graph, without the specification of a concrete path between each node.

##### Control-Related Problems for Objective Functions
A major problem is covering nested structures within loops that require many iterations.
Some approaches try to resolve this by considering branches that miss the target in iterations of the loop, as critical branches.
However, this leads to penalisation of individuals in the first iteration of the loop.

A second problem is the assignment of approach levels for some classes of programs with unstructured control flows.
A solution to this is to use *optimistic* or *pessimistic* approach level allocation strategies.
In an optimistic strategy, a control dependent branching node is allocated its approach level on the basis of the shortest control dependent path from itself to the target node.
In a pessimistic strategy, a branching node is allocated its approach level on the basis of the longest control dependent path to the target node.
Both strategies have different effects on the progress of the search, but it still remains an open problem which strategy works the best in general.

##### Branch-Distance-Related Problems for Objective Functions
The global search techniques still have some problems in hostile search landscapes containing large plateaux or several local optima.
Plateaux are easily created by a simple "flag" variable.
With these types of flags, the evolutionary search performs no better than random search.

A solution is removing a flag from the branch predicate by performing program transformation.
This is however not always possible.

Alternatively a sequence of nodes to be executed prior to the branch predicate containing the flag can be identified.
However, the approach has problems avoiding unrequired assignments to flags within loop bodies.

A second problem is that there exists the possibility that the branch distance calculation deceives the search.

A third problem can occur with nested branch predicates where a solution for subsequent conditions must be found without violating any of the earlier conditions.

##### Applying Variable Dependency Analysis
Variable dependency analysis allows the determination of the subset of input variables that cannot affect the outcome at a branch predicate.
This allows for reduction of the search space.

##### Generating Input Sequences
Another problem for structural test data generation are test objects with internal states.
In these situations an input sequence is required to cover certain structures.

A further problems with state-based systems is their tendency to make use of flag and enumeration variables to control the current state.

##### Use of Evolutionary Algorithms: Encodings and Operators
Early work used binary encoding, but it is common that variables will often only have valid values within a subset of possible bit patterns at the binary level.
Using evolutionary algorithms on binary encoding can cause corruption with restricted types in the crossover and mutation operators.
This problem can be resolved by using real-valued encodings, which removes the need to encode and decode the input vector into and out of a binary format and prevents the variables from going out of range.

#### Future Directions for Search-based Structural Testing
Problems that need further research:
 - Flag and enumeration variables
 - Unstructured control flow and state behaviour
 - Test data cannot be found
 - Does not support programs involving strings and dynamic data structures such as lists, sets, etc
 - Problems with dynamic types including comparison of pointer locations.
 - Complications in object-oriented system due to internal states and polymorphic types.

Future fields of research: programs using information from files and sockets.

### Functional (Black-Box) Testing
Functional (Black-Box) Testing uses metaheuristic search techniques to test the logical behaviour of a system, as described by some form of specification.

#### Generating Test Data from a Z Specification
Z specification describes the state space of the system in a schema consisting of disjunctions, which contain conjunction of input variables and predicates.
Each disjunct is considered as a *route* through the system. Genetic Algorithms are used to search for test data for each route.
Each conjunct is evaluated using a distance based approach, to the branch distance calculations used in Structural testing.
The overall fitness of the route is the summation of the distances for each of its conjuncts.

#### Testing Specification Conformance
Conformance of the implementation to its specification is checked by executing the test object with the generated test data and then validating the output against the specification.
A failure is found when an input situation is discovered that satisfies the pre-condition of a function, but for which the outputs violate the post-condition.

#### Future Directions for Search-based Functional Testing
Search-based functional testing is less active compare to structural testing.
A few downsides:
 - A mapping needs to be provided from the abstract model of the specification to the concrete form of the implementation.
 - Can consist of an extremely large search space.
 - Test sequences may need to be generated to put the system into some valid state in order for the property of interest to be test.

### Grey-box Testing
Grey-box testing combines both structural and functional information for the purpose of testing.

#### Assertion Testing
Assertions specify constraints that apply to some state of a computation. When an assertion evaluates to false, an error has been found in the program.
The assertion code is formed into a function with the original assertion comment region and replaced with a call to the corresponding function.
The goal is then to execute a false assignment to the assertion variable statement within the function and thereafter avoiding all true assignment to the variable.

#### Exception Condition Testing
Similar idea as Assertion Testing, but this technique tries to trigger exceptions.
Problem here was that the Test Data was often not possible when using the software and thus the violations were false positives.

#### Future Directions for Search-based Grey-Box Testing
 - Component-reuse Testing: searching for test data that causes a component to be called where its usage assumptions are broken.
 - Black-Box assertions used as test oracles, offering further automation.

### Non-Functional Testing
In this area there is a large concentration on best and worst-case execution times of real-time systems.

#### Execution Time Testing
Execution time testing involves attempts to find the worst-case execution time (WCET) or the best-case execution time (BCET) of a system in order to determine whether it is compliant with its timing constraints.

##### Static analysis
Static analysis can be used to derive WCET and BCET. This is done by examining the possible execution paths and modelling timing behaviour at the hardware level.
The primary step needs assistance from the programmer, since information is required regarding the infeasible paths, and the maximum number of iterations for each loop appearing in the code.
Major problems with this technique are the possibility of simulation errors and the need for human involvement.

##### Search-based Execution Time Testing
The objective function is the execution time of the system as executed with some input. The search attempts to maximize (WCET) or minimize (BCET).
Search-based techniques cannot guarantee the actual WCET or BCEt, but the best found result can be used to form an interval with the time obtained from static analysis within which the actual extreme execution time most probably lies.

##### Future Directions for Search-based Execution Time Testing
It is important to look into using a combination of static analysis and search-based techniques.
Search-based techniques could be used to verify path feasibility for static analysis.

Further it is possible to combine the objective function with those used by structural test data generation to ensure that timing behavior involving all branches is explored.
Especially procedural code has been researched. It would be interesting extending these techniques to object-oriented software.


#### Future Directions for Search-based Non-Functional Testing
Future research areas include:
 - Resource usage: memory, storage requirements.
 - Memory leak detection
 - Stress testing, security testing, etc.

### Conclusions
*Symbolic Exectuion* evaluates program code in order to build up a system of constraints describing the test goal.
Becomes problematic when using loop and in cases where computer storage location need to be determined.
Alternatively *dynamic approaches* execute the program with some input and examining the effects via some form of instrumentation.
Helps to resolve problems we saw with symbolic execution such as pointer locations, which are known at run-time.

Metaheursitic Techniques allow a definition of an objective function, which is used to guide test data generation.
The two main types of objectives are *Coverage-Oriented* (objective function: number of program structures executed) and *Structure-Oriented* (objective function: guides search to cover each individual structural element).

*Search-based test data generation approaches*  to *functional testing* have focused on finding inputs such that the program does not meet the specifications. 

*Grey-box* test data generation approaches combine methods used in generating structural and functional testing.
Structure-oriented white-box testing techniques can be used to attempt to induce violations of assertions.

